{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797d2e43-d1aa-4336-a7b7-c2247577d58a",
   "metadata": {},
   "source": [
    "<h1 align='center'> 영상처리 프로그래밍 실습 10</h1>\n",
    "\n",
    "<h6 align='right'> 2025. 6. 5. </h6>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5adea0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "- 파일 이름에서 00000000을 자신의 학번으로, name을 자신의 이름으로 수정하세요.\n",
    "\n",
    "- 다음 줄에 자신의 이름, 학번, 학과(전공)을 적으세요.\n",
    "\n",
    "* 이름: 이선재  &nbsp;&nbsp;          학번:  20227123   &nbsp;&nbsp;         학과(전공): 빅데이터\n",
    "    \n",
    "</div>\n",
    "\n",
    "- JupyterLab 문서의 최신 버전은 [JupyterLab Documentation](https://jupyterlab.readthedocs.io/en/stable/index.html#/)을  참고하라\n",
    "\n",
    "- Markdown은 [Markdown Guide](https://www.markdownguide.org/)를 참고하라.\n",
    "- [Markdown Cheat Sheet](https://www.markdownguide.org/cheat-sheet/)\n",
    "- 실험에 사용할 영상은 [영상 데이터베이스](https://drive.google.com/drive/folders/1zbjtkf9nHy9VniuLI4wHilbrN_JBvhYi)에서 다운로드할 것\n",
    "\n",
    "\n",
    "* 제출 마감: 6월 11일 (수) 오후 10:00까지 최종본을 SmartLEAD제출\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f83a4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 1 (Sample)</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e117ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV version 4.11.0\n",
      "NumPy version 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "print(\"OpenCV version\", cv2.__version__)\n",
    "print(\"NumPy version\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f702ab1-eee0-488a-bd3f-f4c11f2fe1e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 문제 1. \n",
    " \n",
    "다음 조건을 만족하는 함수 perspective_projection_transform(img) 함수를 작성하라.\n",
    "\n",
    "- OpenCV의 윈도우을 만들고, 입력 영상을 왼쪽에, 입력 영상의 복사본을 오른쪽에 나란히 표시한다\n",
    "- 왼쪽 영상의 4 각형의 네 점의 위치를 다음 순서대로 마우스로 클릭하면 4 각형을 그린다.\n",
    "- 왼 꼭짓점에서 반시계 방향으로 지정한다\n",
    "- 사각형이 완성되면 perspective projection transform된 영상을 오른쪽에 표시한다.\n",
    "- perspective projection transform 출력 영상의 크기는 입력 영상의 크기와 같다\n",
    "\n",
    "다음 그림은 'social-media_640.jpg' 파일을 이 프로그램에 적용한 결과 예이다.\n",
    "\n",
    "![perspective_Tx_Sosical_media](perspective_Tx_Sosical_media.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23ff8807-727b-4038-b009-b38a907904ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 마우스 클릭한 점들을 저장할 리스트\n",
    "points = []\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global points, img_copy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and len(points) < 4:\n",
    "        points.append((x, y))\n",
    "        # 점 찍기\n",
    "        cv2.circle(img_copy, (x, y), 5, (0, 255, 0), -1)\n",
    "        if len(points) > 1:\n",
    "            cv2.line(img_copy, points[-2], points[-1], (255, 0, 0), 2)\n",
    "        # 마지막 점일 경우 첫점과 연결\n",
    "        if len(points) == 4:\n",
    "            cv2.line(img_copy, points[3], points[0], (255, 0, 0), 2)\n",
    "\n",
    "def perspective_projection_transform(img):\n",
    "    global points, img_copy\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    # 왼쪽 원본 + 오른쪽 복사본을 옆으로 붙이기\n",
    "    display_img = np.hstack((img.copy(), img.copy()))\n",
    "    img_copy = display_img.copy()\n",
    "\n",
    "    cv2.namedWindow(\"Perspective Transform\")\n",
    "    cv2.setMouseCallback(\"Perspective Transform\", mouse_callback)\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow(\"Perspective Transform\", img_copy)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # ESC 키로 종료\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # 4점 선택되면 변환 수행\n",
    "        if len(points) == 4:\n",
    "            # 변환 대상 점 (사각형)\n",
    "            dst_pts = np.float32([\n",
    "            [0, 0],          # 왼쪽 위\n",
    "            [0, h - 1],      # 왼쪽 아래\n",
    "            [w - 1, h - 1],  # 오른쪽 아래\n",
    "            [w - 1, 0]       # 오른쪽 위\n",
    "        ])\n",
    "\n",
    "        # perspective transform\n",
    "        M = cv2.getPerspectiveTransform(np.float32(points), dst_pts)\n",
    "        warped = cv2.warpPerspective(img, M, (w, h))\n",
    "\n",
    "        # 오른쪽 영역에 결과 붙이기\n",
    "        img_copy[:, w:] = warped\n",
    "\n",
    "        # 변환 완료 후 다시 클릭 못하게 막기\n",
    "        points.clear()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 예시 실행\n",
    "# 순서 왼쪽 위, 오른쪽 위, 오른쪽 아래, 왼쪽 아래\n",
    "img = cv2.imread('social-media_640.jpg')\n",
    "perspective_projection_transform(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61969cf9",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 1 (기초 구현) - chat gpt 4o</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "### 문제 1. \n",
    " \n",
    "다음 조건을 만족하는 함수 perspective_projection_transform(img) 함수를 작성하라.\n",
    "\n",
    "- OpenCV의 윈도우을 만들고, 입력 영상을 왼쪽에, 입력 영상의 복사본을 오른쪽에 나란히 표시한다\n",
    "- 왼쪽 영상의 4 각형의 네 점의 위치를 다음 순서대로 마우스로 클릭하면 4 각형을 그린다.\n",
    "- 사각형이 완성되면 perspective projection transform된 영상을 오른쪽에 표시한다.\n",
    "- perspective projection transform 출력 영상의 크기는 입력 영상의 크기와 같다\n",
    "\n",
    "다음 그림은 'social-media_640.jpg' 파일을 이 프로그램에 적용한 결과 예이다.\n",
    "\n",
    "![perspective_Tx_Sosical_media](perspective_Tx_Sosical_media.png)\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "다음은 요구사항을 충족하는 OpenCV 기반의 `perspective_projection_transform(img)` 함수 전체 코드입니다.\n",
    "\n",
    "이 코드는:\n",
    "\n",
    "* 입력 이미지와 같은 크기의 오른쪽 복사본을 포함한 창을 표시하고,\n",
    "* 사용자가 마우스로 왼쪽 이미지에 4점을 클릭하면 사각형을 그리고,\n",
    "* 이 사각형에 대해 **투시 변환(perspective transform)** 을 수행하여,\n",
    "* 오른쪽 이미지 영역에 결과를 표시합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 전체 코드\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# 마우스 클릭한 점들을 저장할 리스트\n",
    "points = []\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global points, img_copy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and len(points) < 4:\n",
    "        points.append((x, y))\n",
    "        # 점 찍기\n",
    "        cv2.circle(img_copy, (x, y), 5, (0, 255, 0), -1)\n",
    "        if len(points) > 1:\n",
    "            cv2.line(img_copy, points[-2], points[-1], (255, 0, 0), 2)\n",
    "        # 마지막 점일 경우 첫점과 연결\n",
    "        if len(points) == 4:\n",
    "            cv2.line(img_copy, points[3], points[0], (255, 0, 0), 2)\n",
    "\n",
    "def perspective_projection_transform(img):\n",
    "    global points, img_copy\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    # 왼쪽 원본 + 오른쪽 복사본을 옆으로 붙이기\n",
    "    display_img = np.hstack((img.copy(), img.copy()))\n",
    "    img_copy = display_img.copy()\n",
    "\n",
    "    cv2.namedWindow(\"Perspective Transform\")\n",
    "    cv2.setMouseCallback(\"Perspective Transform\", mouse_callback)\n",
    "\n",
    "    while True:\n",
    "        cv2.imshow(\"Perspective Transform\", img_copy)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # ESC 키로 종료\n",
    "        if key == 27:\n",
    "            break\n",
    "\n",
    "        # 4점 선택되면 변환 수행\n",
    "        if len(points) == 4:\n",
    "            # 변환 대상 점 (사각형)\n",
    "            dst_pts = np.float32([\n",
    "                [0, 0],\n",
    "                [w - 1, 0],\n",
    "                [w - 1, h - 1],\n",
    "                [0, h - 1]\n",
    "            ])\n",
    "\n",
    "            # perspective transform\n",
    "            M = cv2.getPerspectiveTransform(np.float32(points), dst_pts)\n",
    "            warped = cv2.warpPerspective(img, M, (w, h))\n",
    "\n",
    "            # 오른쪽 영역에 결과 붙이기\n",
    "            img_copy[:, w:] = warped\n",
    "\n",
    "            # 변환 완료 후 다시 클릭 못하게 막기\n",
    "            points.clear()\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 예시 실행\n",
    "# img = cv2.imread('social-media_640.jpg')\n",
    "# perspective_projection_transform(img)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 사용법\n",
    "\n",
    "1. 이미지를 불러오고 `perspective_projection_transform(img)`에 넘겨 실행하세요.\n",
    "2. 왼쪽 이미지에서 **시계 방향 또는 반시계 방향으로 4점**을 클릭하세요.\n",
    "3. 사각형이 자동으로 그려지고, 오른쪽 이미지에 투시 변환 결과가 나타납니다.\n",
    "4. `ESC` 키를 누르면 창이 닫힙니다.\n",
    "\n",
    "---\n",
    "\n",
    "필요 시, 클릭한 좌표 출력이나 여러번 다시 시도 기능도 추가할 수 있습니다. 원하시나요?\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b537e47e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 2 (오류 수정) - claude 3.5</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "문제 1번에 왼쪽 위부터 반시계 방향으로 하면 정상적으로 보여주도록 해줘 지금 순서가 반대로 대어 있어\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "네, 현재 코드에서는 왼쪽 위부터 반시계 방향으로 클릭하도록 되어있지만, 실제 변환 시점에서 순서가 반대로 되어있네요. `perspective_projection_transform` 함수를 수정하겠습니다.\n",
    "\n",
    "죄송합니다. 다시 한번 시도해보겠습니다.\n",
    "\n",
    "죄송합니다. 파일 수정이 제대로 적용되지 않았네요. 다시 한번 시도해보겠습니다.\n",
    "\n",
    "죄송합니다. Jupyter Notebook 파일의 수정이 예상보다 어려운 것 같습니다. 현재 코드의 문제점과 해결 방법을 설명드리겠습니다:\n",
    "\n",
    "현재 코드에서는 `dst_pts`가 다음과 같이 정의되어 있습니다:\n",
    "```python\n",
    "dst_pts = np.float32([\n",
    "    [0, 0],          # 왼쪽 위\n",
    "    [w - 1, 0],      # 오른쪽 위\n",
    "    [w - 1, h - 1],  # 오른쪽 아래\n",
    "    [0, h - 1]       # 왼쪽 아래\n",
    "])\n",
    "```\n",
    "\n",
    "이를 다음과 같이 수정해야 합니다:\n",
    "```python\n",
    "dst_pts = np.float32([\n",
    "    [0, 0],          # 왼쪽 위\n",
    "    [0, h - 1],      # 왼쪽 아래\n",
    "    [w - 1, h - 1],  # 오른쪽 아래\n",
    "    [w - 1, 0]       # 오른쪽 위\n",
    "])\n",
    "```\n",
    "\n",
    "이렇게 수정하면:\n",
    "1. 왼쪽 위 (0, 0)에서 시작\n",
    "2. 왼쪽 아래 (0, h-1)로 이동\n",
    "3. 오른쪽 아래 (w-1, h-1)로 이동\n",
    "4. 오른쪽 위 (w-1, 0)로 이동\n",
    "\n",
    "이렇게 반시계 방향으로 순서가 맞춰지게 됩니다.\n",
    "\n",
    "Jupyter Notebook 파일을 직접 수정하시려면:\n",
    "1. 노트북을 열어서 해당 셀을 찾으세요\n",
    "2. `dst_pts` 배열의 순서를 위와 같이 수정하세요\n",
    "3. 셀을 실행하시면 됩니다\n",
    "\n",
    "이렇게 하면 왼쪽 위부터 반시계 방향으로 클릭했을 때 정상적으로 변환이 이루어질 것입니다.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0b1e4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 3 (np.hstack) - chat gpt 4o</summary>\n",
    "\n",
    "### 질문\n",
    "---\n",
    "np.hstack((img.copy(), img.copy())) 은 왜 사용한거야?\n",
    "\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "\n",
    "좋은 질문입니다!\n",
    "`np.hstack((img.copy(), img.copy()))` 의 의미와 **이유**는 아래와 같습니다:\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 `np.hstack((img.copy(), img.copy()))` 의미\n",
    "\n",
    "이 코드는:\n",
    "\n",
    "```python\n",
    "np.hstack((img.copy(), img.copy()))\n",
    "```\n",
    "\n",
    "* `img.copy()`로 **입력 이미지를 복사**한 것을 두 번 준비하고,\n",
    "* `np.hstack(...)`을 이용해 **좌우로 나란히(horizontal stack)** 붙이는 것입니다.\n",
    "\n",
    "즉, 하나는 왼쪽에, 하나는 오른쪽에 나타나게 됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 왜 이렇게 했을까?\n",
    "\n",
    "#### ✅ 이유 1: **왼쪽은 원본**, 오른쪽은 **결과 표시용**\n",
    "\n",
    "* **왼쪽 이미지**: 사용자가 4점을 클릭할 입력용 원본\n",
    "* **오른쪽 이미지**: 투시 변환 결과(perspective transform result)를 표시하기 위한 공간\n",
    "\n",
    "#### ✅ 이유 2: **하나의 윈도우에 두 이미지를 함께 보여주기 위함**\n",
    "\n",
    "* 하나의 OpenCV 창에서 `imshow`로 보여줄 수 있는 이미지는 1개뿐입니다.\n",
    "* 그래서 두 이미지를 붙여서 하나로 만든 후 표시해야 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 예시: 입력 이미지가 `640x480`이면?\n",
    "\n",
    "```python\n",
    "img.shape = (480, 640, 3)\n",
    "display_img = np.hstack((img.copy(), img.copy()))\n",
    "```\n",
    "\n",
    "➡ `display_img.shape = (480, 1280, 3)`\n",
    "즉, 가로로 두 배 넓어진 이미지가 생성됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 요약\n",
    "\n",
    "| 코드                      | 설명                                   |\n",
    "| ----------------------- | ------------------------------------ |\n",
    "| `img.copy()`            | 원본 이미지 복사                            |\n",
    "| `np.hstack((..., ...))` | 복사본 둘을 **가로로 붙임**                    |\n",
    "| 목적                      | 한 창에 **입력 이미지 + 결과 이미지** 나란히 보여주기 위함 |\n",
    "\n",
    "---\n",
    "\n",
    "필요하다면 `np.vstack`을 써서 세로로 붙일 수도 있어요.\n",
    "더 궁금한 점 있으신가요? 😊\n",
    "\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9c7d73",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 4 (클릭 저장 작업) - chat gpt 4o</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "코드에서 내가 클릭을 하면 4개의 좌표를 저장하는 작업을 어디서 하는거야?\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "당신이 작성한 코드에서 **마우스로 클릭한 4개의 좌표를 저장하는 작업**은 함수 `mouse_callback()` 안에서 이루어집니다.\n",
    "그 함수는 `cv2.setMouseCallback()`을 통해 등록됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 클릭 좌표 저장 위치\n",
    "\n",
    "```python\n",
    "cv2.setMouseCallback(\"Perspective Transform\", mouse_callback)\n",
    "```\n",
    "\n",
    "⬆️ 이 줄이 핵심입니다.\n",
    "OpenCV는 `\"Perspective Transform\"`이라는 윈도우에서 **마우스 이벤트가 발생할 때마다** `mouse_callback` 함수를 호출하게 됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 `mouse_callback()` 함수의 역할\n",
    "\n",
    "이 함수는 이렇게 정의되어 있어야 합니다 (앞에서 전체 코드 참고):\n",
    "\n",
    "```python\n",
    "points = []  # 전역 리스트\n",
    "\n",
    "def mouse_callback(event, x, y, flags, param):\n",
    "    global points, img_copy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and len(points) < 4:\n",
    "        points.append((x, y))  # ← 여기서 좌표를 저장합니다\n",
    "        cv2.circle(img_copy, (x, y), 5, (0, 255, 0), -1)\n",
    "        if len(points) > 1:\n",
    "            cv2.line(img_copy, points[-2], points[-1], (255, 0, 0), 2)\n",
    "        if len(points) == 4:\n",
    "            cv2.line(img_copy, points[3], points[0], (255, 0, 0), 2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 정리하면:\n",
    "\n",
    "| 부분                          | 설명                                 |\n",
    "| --------------------------- | ---------------------------------- |\n",
    "| `cv2.setMouseCallback(...)` | 마우스 이벤트를 등록                        |\n",
    "| `mouse_callback()` 함수       | 클릭 시 `(x, y)` 좌표를 `points` 리스트에 저장 |\n",
    "| `points.append((x, y))`     | 좌표 저장하는 코드 (좌클릭 시)                 |\n",
    "\n",
    "---\n",
    "\n",
    "즉, **클릭 시 좌표 저장은 `mouse_callback` 함수에서 이루어지고**,\n",
    "`perspective_projection_transform()` 함수에서는 `points`가 4개가 되면 변환을 수행합니다.\n",
    "\n",
    "필요하다면 이 흐름을 시각적으로 설명해드릴 수도 있어요!\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964b69cd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 1 (기초 구현)</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cead247-a30f-4fa5-9442-6fbda016fe3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 문제 2.\n",
    "\n",
    "'beach_640.jpg' 파읽을 읽고 k-Means algorithm을 이용해서 5 개의 색만으로 벡터 양자화한 후에,\n",
    "원 영상과 벡터 양자화된 영상을 나란히 표시하라.\n",
    "\n",
    "다음 그림은 실행 결과 예이다.\n",
    "\n",
    "![beach_cluster_5](beach_cluster_5.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7d9ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def kmeans_color_quantization(img, K=5):\n",
    "    Z = img.reshape((-1, 3))  # (H×W, 3)로 reshape\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    # K-means parameters\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    attempts = 10\n",
    "\n",
    "    # k-means 알고리즘 적용\n",
    "    ret, labels, centers = cv2.kmeans(Z, K, None, criteria, attempts, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    centers = np.uint8(centers)  # 색상은 정수여야 함\n",
    "    quantized = centers[labels.flatten()]  # 각 픽셀에 클러스터 색상 적용\n",
    "    quantized_img = quantized.reshape((img.shape))  # 다시 원본 크기로\n",
    "\n",
    "    return quantized_img\n",
    "\n",
    "def show_quantized_result():\n",
    "    img = cv2.imread('beach_640.jpg')\n",
    "    if img is None:\n",
    "        print(\"이미지를 불러올 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    quantized_img = kmeans_color_quantization(img, K=5)\n",
    "\n",
    "    # 원본과 결과 나란히 표시\n",
    "    combined = np.hstack((img, quantized_img))\n",
    "    cv2.imshow(\"Original (Left) + Quantized (Right, K=5)\", combined)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 실행\n",
    "show_quantized_result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895aea3",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 코드 설명 (클릭하여 펼치기)</summary>\n",
    "\n",
    "이러한 내용을 문제 2번 코드 밑에 열고 닫을 수 있도록 편의성있게 작성해줘\n",
    "\n",
    "### 1. 함수 구조\n",
    "```python\n",
    "def kmeans_color_quantization(img, K=5):\n",
    "    Z = img.reshape((-1, 3))  # (H×W, 3)로 reshape\n",
    "    Z = np.float32(Z)\n",
    "```\n",
    "- 입력 이미지를 k-means 알고리즘에 적합한 형태로 변환\n",
    "- 이미지 크기: H(높이) × W(너비) × 3(RGB 채널)\n",
    "- 각 픽셀을 하나의 데이터 포인트로 변환\n",
    "\n",
    "### 2. K-means 파라미터 설정\n",
    "```python\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "attempts = 10\n",
    "```\n",
    "- 알고리즘 종료 조건 설정\n",
    "  - 최대 10번 반복\n",
    "  - 정확도 1.0 이하에서 종료\n",
    "- 10번의 시도 중 최적의 결과 선택\n",
    "\n",
    "### 3. K-means 알고리즘 적용\n",
    "```python\n",
    "ret, labels, centers = cv2.kmeans(Z, K, None, criteria, attempts, cv2.KMEANS_RANDOM_CENTERS)\n",
    "```\n",
    "- 입력 데이터를 K개의 클러스터로 군집화\n",
    "- 반환값:\n",
    "  - `ret`: 최적화된 목적 함수 값\n",
    "  - `labels`: 각 픽셀의 클러스터 번호\n",
    "  - `centers`: 각 클러스터의 대표 색상\n",
    "\n",
    "### 4. 결과 이미지 생성\n",
    "```python\n",
    "centers = np.uint8(centers)  # 색상은 정수여야 함\n",
    "quantized = centers[labels.flatten()]  # 각 픽셀에 클러스터 색상 적용\n",
    "quantized_img = quantized.reshape((img.shape))  # 다시 원본 크기로\n",
    "```\n",
    "- 클러스터 중심점을 8비트 정수형으로 변환\n",
    "- 각 픽셀을 해당 클러스터의 대표 색상으로 대체\n",
    "- 원본 이미지 크기로 재구성\n",
    "\n",
    "### 5. 결과 표시\n",
    "```python\n",
    "def show_quantized_result():\n",
    "    # 이미지 로드 및 양자화\n",
    "    # 원본과 결과를 나란히 표시\n",
    "```\n",
    "- 원본 이미지와 양자화된 이미지를 가로로 연결하여 표시\n",
    "- 왼쪽: 원본 이미지\n",
    "- 오른쪽: 5가지 색상으로 양자화된 이미지\n",
    "\n",
    "### 주요 목적\n",
    "1. 이미지의 모든 픽셀을 5개의 대표 색상으로 군집화\n",
    "2. 각 픽셀을 가장 가까운 대표 색상으로 대체\n",
    "3. 이미지의 색상 수를 줄이면서 주요 색상 정보 유지\n",
    "\n",
    "### 활용 분야\n",
    "- 이미지 압축\n",
    "- 스타일 변환\n",
    "- 이미지 분석\n",
    "- 데이터 시각화\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dcc7b0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 (K-means가 이미지 색상 축소(양자화)에 효과적인가?)</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "이미지의 색상을 줄이는 데 왜 K-means가 적합한가요? 다른 방법과 비교했을 때 어떤 이점이 있나요?\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "K-means는 다차원 공간(여기서는 RGB 색상 공간)에서 비슷한 색상들을 하나의 클러스터로 묶는 알고리즘입니다.\n",
    "이미지에는 수만 가지 색상이 있을 수 있지만, 실제로는 시각적으로 유사한 색상들이 많습니다.\n",
    "K-means는 그런 색상들을 효과적으로 묶고, 그 중심값을 대표 색으로 사용함으로써 시각적 품질을 크게 해치지 않으면서도 색상 수를 줄일 수 있습니다.\n",
    "\n",
    "✅ 대체 방법과 비교:\n",
    "\n",
    "단순 색상 양자화 (e.g., RGB를 64단계로 줄이기): 경계가 명확해져 품질이 떨어질 수 있음.\n",
    "\n",
    "Median Cut, Octree Quantization 등도 존재하지만, K-means는 유클리디안 거리 기반의 최적화된 색 분할을 제공한다는 점에서 강력합니다.`\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb4933f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 (왜 np.float32로 변환하나요?)</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "왜 이미지 데이터를 float32로 바꾸는 게 중요할까요? 그냥 정수형으로 해도 되지 않나요?\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "OpenCV의 cv2.kmeans()는 클러스터 중심 계산과 거리 계산을 부동소수점으로 수행해야 합니다.\n",
    "정수형(uint8)으로 연산하면 거리 계산 정확도가 낮아지거나 오버플로우/언더플로우 문제가 발생할 수 있습니다.\n",
    "\n",
    "또한, cv2.kmeans()는 내부적으로 OpenCV의 C++ API를 호출하는데, 이 API는 float32 형식의 입력을 기대합니다.\n",
    "정수형으로 제공할 경우 예외가 발생하거나 잘못된 결과를 낼 수 있습니다.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312a5e7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 (왜 k-means의 결과가 항상 같지 않을 수 있나요?)</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "같은 K 값으로 여러 번 실행했을 때 결과가 다를 수 있는데, 왜 그런가요?\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "K-means는 랜덤 초기 중심점(random init) 으로 시작하므로, 서로 다른 결과가 나올 수 있습니다.\n",
    "이를 보완하기 위해 attempts=10처럼 여러 번 초기화하고 그 중 최적의 결과를 선택하도록 설정합니다.\n",
    "\n",
    "➡️ K-means는 로컬 최적해(local minima)에 빠지기 쉬운 알고리즘입니다.\n",
    "그래서 cv2.KMEANS_RANDOM_CENTERS는 결과 품질에 중요한 영향을 줍니다.\n",
    "\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1866241",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 (색상 공간을 바꾸는 것이 성능에 어떤 영향을 줄 수 있을까?)</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "RGB가 아닌 다른 색상 공간(HSV, Lab 등)을 사용하면 결과에 어떤 차이가 생길까요?\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "RGB는 사람의 시각적 인식과는 달리 선형적인 색상 공간입니다.\n",
    "즉, RGB에서의 거리 계산은 실제 색상 인식 차이와 다를 수 있습니다.\n",
    "\n",
    "CIELab 공간은 사람이 인식하는 색상 차이를 더 잘 반영합니다.\n",
    "\n",
    "HSV는 색조(Hue)와 채도(Saturation), 명도(Value)를 분리하여 조절이 쉬움.\n",
    "\n",
    "➡️ 색상 공간을 Lab으로 변환한 후 K-means를 적용하면 더 시각적으로 일관된 양자화 결과를 얻을 수 있습니다.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8640e788-5e7e-475c-bab3-8a6695d3d16a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 문제 3.\n",
    "\n",
    "문제 2의 프로그램을 다음과 같이 수정하라.\n",
    "\n",
    "- OpenCV의 trackBar interface를 이용해서 k-Means의 cluster 개수를 조정하면서 벡터 양자화된 영상을 윈도우에 표시하라. 단, cluster 개수의 최솟값은 1로 설정하고, cluster의 개수가 1인 경우에는 원 영상을 표시하라. 따라서 실제 cluster의 최솟값은 2가 된다.\n",
    "\n",
    "\n",
    "다음 그림은 실행 결과 예이다.\n",
    "\n",
    "![beach_cluster_tarckbar](beach_cluster_tarckbar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c1043c1-4a4d-497e-8b28-9211eb6276cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def kmeans_color_quantization(img, K):\n",
    "    Z = img.reshape((-1, 3))\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    attempts = 10\n",
    "\n",
    "    ret, labels, centers = cv2.kmeans(Z, K, None, criteria, attempts, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    quantized = centers[labels.flatten()]\n",
    "    quantized_img = quantized.reshape((img.shape))\n",
    "\n",
    "    return quantized_img\n",
    "\n",
    "def on_trackbar(val):\n",
    "    global original_img\n",
    "\n",
    "    if val == 0:\n",
    "        combined = np.hstack((original_img, original_img))\n",
    "    else:\n",
    "        k = val + 1  # val=1이면 k=2\n",
    "        quantized_img = kmeans_color_quantization(original_img, k)\n",
    "        combined = np.hstack((original_img, quantized_img))\n",
    "\n",
    "    cv2.imshow(\"KMeans Quantization\", combined)\n",
    "\n",
    "def run_kmeans_with_trackbar():\n",
    "    global original_img\n",
    "\n",
    "    original_img = cv2.imread('beach_640.jpg')\n",
    "    if original_img is None:\n",
    "        print(\"이미지를 불러올 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    window_name = \"KMeans Quantization\"\n",
    "    cv2.namedWindow(window_name)\n",
    "    cv2.createTrackbar(\"K (0:원본, 1~18 → K=2~20)\", window_name, 0, 18, on_trackbar)\n",
    "\n",
    "    on_trackbar(0)\n",
    "\n",
    "    while True:\n",
    "        # 창이 닫혔는지 확인\n",
    "        if cv2.getWindowProperty(window_name, cv2.WND_PROP_VISIBLE) < 1:\n",
    "            break\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ESC 키로 종료\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 실행\n",
    "run_kmeans_with_trackbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207d616",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 1 (기초 구현) - chat gpt 4o</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "문제에 맞게 구현해줘\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "아래는 **문제 3**에서 요구한 대로 `OpenCV의 trackBar`를 이용하여 **클러스터 수(K)** 를 조정하면서 실시간으로 `k-Means` 벡터 양자화를 수행하는 전체 코드입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 핵심 기능 요약\n",
    "\n",
    "* `cv2.createTrackbar`를 이용해 클러스터 개수를 조정\n",
    "* `K=1`일 때는 **원본 이미지 그대로 표시**\n",
    "* `K≥2`일 때는 **k-Means 벡터 양자화된 이미지 표시**\n",
    "* 결과는 하나의 OpenCV 창에서 **실시간 갱신**\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 전체 코드\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def kmeans_color_quantization(img, K):\n",
    "    Z = img.reshape((-1, 3))\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    attempts = 10\n",
    "\n",
    "    ret, labels, centers = cv2.kmeans(Z, K, None, criteria, attempts, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    quantized = centers[labels.flatten()]\n",
    "    quantized_img = quantized.reshape((img.shape))\n",
    "\n",
    "    return quantized_img\n",
    "\n",
    "def on_trackbar(val):\n",
    "    global original_img\n",
    "\n",
    "    k = cv2.getTrackbarPos(\"K (min 1)\", \"KMeans Quantization\")\n",
    "\n",
    "    # 최소 클러스터 1: 원본 그대로\n",
    "    if k <= 1:\n",
    "        combined = np.hstack((original_img, original_img))\n",
    "    else:\n",
    "        quantized_img = kmeans_color_quantization(original_img, k)\n",
    "        combined = np.hstack((original_img, quantized_img))\n",
    "\n",
    "    cv2.imshow(\"KMeans Quantization\", combined)\n",
    "\n",
    "def run_kmeans_with_trackbar():\n",
    "    global original_img\n",
    "\n",
    "    original_img = cv2.imread('beach_640.jpg')\n",
    "    if original_img is None:\n",
    "        print(\"이미지를 불러올 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # 창 생성 및 트랙바 설정\n",
    "    cv2.namedWindow(\"KMeans Quantization\")\n",
    "    cv2.createTrackbar(\"K (min 1)\", \"KMeans Quantization\", 1, 10, on_trackbar)\n",
    "\n",
    "    # 초기 표시\n",
    "    on_trackbar(1)\n",
    "\n",
    "    while True:\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == 27:  # ESC\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 실행\n",
    "# run_kmeans_with_trackbar()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 실행 방법\n",
    "\n",
    "1. `beach_640.jpg` 파일이 같은 폴더에 있어야 합니다.\n",
    "2. 마지막 줄 `run_kmeans_with_trackbar()`를 호출하면 실행됩니다.\n",
    "3. 윈도우의 트랙바를 움직여서 K 값을 1\\~10 범위로 조정하세요.\n",
    "\n",
    "   * `K = 1` → 원본\n",
    "   * `K ≥ 2` → kMeans 벡터 양자화 이미지\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 추가 팁\n",
    "\n",
    "* 트랙바 최대값은 `10`으로 설정했지만, 원하면 `20`, `50` 등으로 확장 가능합니다.\n",
    "* 성능을 위해 이미지 크기를 줄여 처리하거나 `cv2.resize()`를 써도 좋습니다.\n",
    "\n",
    "필요하면 저장 기능, 속도 개선, UI 꾸미기도 추가해 드릴 수 있어요.\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4446de2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 2 (기능 구현) - chat gpt 4o</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "최대 20개로 해주고 트랙바에 0은 삭제 부탁해\n",
    "---\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "물론입니다! 다음은 다음 조건을 모두 반영한 코드입니다:\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 수정 사항\n",
    "\n",
    "* ✅ 클러스터 개수(K)의 **최대값은 20**\n",
    "* ✅ 트랙바의 **최소값은 2** (1 또는 0은 제거)\n",
    "* ✅ 트랙바 이름은 `\"K (2~20)\"`\n",
    "\n",
    "---\n",
    "\n",
    "### 🧪 최종 코드\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def kmeans_color_quantization(img, K):\n",
    "    Z = img.reshape((-1, 3))\n",
    "    Z = np.float32(Z)\n",
    "\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    attempts = 10\n",
    "\n",
    "    ret, labels, centers = cv2.kmeans(Z, K, None, criteria, attempts, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    centers = np.uint8(centers)\n",
    "    quantized = centers[labels.flatten()]\n",
    "    quantized_img = quantized.reshape((img.shape))\n",
    "\n",
    "    return quantized_img\n",
    "\n",
    "def on_trackbar(val):\n",
    "    global original_img\n",
    "\n",
    "    # 트랙바 값에 +2 해서 실제 K 값으로 사용\n",
    "    k = val + 2\n",
    "\n",
    "    quantized_img = kmeans_color_quantization(original_img, k)\n",
    "    combined = np.hstack((original_img, quantized_img))\n",
    "    cv2.imshow(\"KMeans Quantization\", combined)\n",
    "\n",
    "def run_kmeans_with_trackbar():\n",
    "    global original_img\n",
    "\n",
    "    original_img = cv2.imread('beach_640.jpg')\n",
    "    if original_img is None:\n",
    "        print(\"이미지를 불러올 수 없습니다.\")\n",
    "        return\n",
    "\n",
    "    # 창 및 트랙바 생성\n",
    "    cv2.namedWindow(\"KMeans Quantization\")\n",
    "    cv2.createTrackbar(\"K (2~20)\", \"KMeans Quantization\", 0, 18, on_trackbar)\n",
    "    # 0~18 이므로 실제 값은 2~20\n",
    "\n",
    "    # 초기 표시 (K=2)\n",
    "    on_trackbar(0)\n",
    "\n",
    "    while True:\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ESC 키로 종료\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# 실행\n",
    "# run_kmeans_with_trackbar()\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 동작 요약\n",
    "\n",
    "* 트랙바 값 범위는 `0~18`, 실제 K는 `val + 2` → `2~20`\n",
    "* 처음 실행 시 `K = 2`로 초기 표시\n",
    "* 원본과 양자화 이미지를 **좌우로 나란히** 보여줌\n",
    "\n",
    "---\n",
    "\n",
    "원하시면 \"K 값 표시 텍스트\"나 이미지 저장 버튼도 추가해 드릴 수 있어요. 😊\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa5aa9a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>📝 질문과 답 (왜 색상 양자화에 K-means 알고리즘이 적합한가요?)</summary>\n",
    "\n",
    "### 질문 \n",
    "---\n",
    "이미지의 색상을 줄이려면 다른 방법도 있을 텐데, 왜 굳이 K-means를 사용하는 걸까요?\n",
    "\n",
    "\n",
    "### 답변\n",
    "---\n",
    "이미지에는 수천~수만 가지 색상이 포함되지만, 많은 색상들이 서로 비슷합니다. K-means는 이런 비슷한 색들을 군집화(clustering) 하여 대표 색상 중심(centroid) 으로 묶어줍니다.\n",
    "\n",
    "이 방식은 다음과 같은 이점을 가집니다:\n",
    "\n",
    "색상 수를 줄이면서도 시각적으로 유사한 품질을 유지\n",
    "\n",
    "압축률 향상\n",
    "\n",
    "엣지 검출, 물체 분할 등 후속 처리 전 단계로 유용\n",
    "\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
